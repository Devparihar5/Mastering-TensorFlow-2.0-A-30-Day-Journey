{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2 Three Types of Graph\n",
    "\n",
    "\n",
    "There are three types of graph: static, dynamic, and Autograph.\n",
    "\n",
    "TensorFlow 1.X used static graph, which firstly creating the graph by various operators and then open a `Session` to execute the graph.\n",
    "\n",
    "For TensorFlow 2.X, dynamic graph is used. The operator will be added to the invisible default graph and executed instantaneously after its usage; there is no need to create a `Session`.\n",
    "\n",
    "Using dynamic graph (i.e. Eager Execution) is convenient for debugging, as it improves performance of TensorFlow code just as original Python code, with possibilities of log output and flow control, etc.\n",
    "\n",
    "The drawback of dynamic graph is a relatively lower execution efficiency comparing to static graph. This is because multiple times of communication between the Pythona thread and the C++ thread of TensorFlow is required for dynamic graph, while the static graph is executed almost all on the TensorFlow kernel using C++ code with higher efficiency. What's more, the static graph optimizes the computation, reducing the steps that are not relevant to the result.\n",
    "\n",
    "It is possible to use the decorator `@tf.function` to construct code by converting normal Python function to TensorFlow graph. Executing this function is identical to executing `Session` in TensorFlow 1.X. This method, which uses decorator `@tf.function` to create static graph, is called Autograph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to Graph\n",
    "\n",
    "\n",
    "The graph consists of nodes and edges.\n",
    "\n",
    "The node represent operator, while the edge represents the dependencies between the operators.\n",
    "\n",
    "The solid edge (line) represents the dependency with data (tensor) transmission.\n",
    "\n",
    "The dotted edge (line) represents the dependency of control, i.e. the order of execution.\n",
    "\n",
    "\n",
    "![](https://www.bing.com/images/blob?bcid=qGeoDQiuC-0FFg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Static Graph\n",
    "\n",
    "\n",
    "In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in `Session`.\n",
    "\n",
    "<!-- #region -->\n",
    "**Example of Static Graph in TensorFlow 1.X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the computation using TensorFlow operations\n",
    "def join_strings(x, y):\n",
    "    return tf.strings.join([x, y], separator=' ')\n",
    "\n",
    "# Execute the computation\n",
    "result = join_strings(\"hello\", \"world\")\n",
    "print(result.numpy().decode())  # Convert the tensor to a string and print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #endregion -->\n",
    "\n",
    "**The Static Graph in TensorFlow2.0 as a memorial**\n",
    "\n",
    "In order to be compatible to the old versions,  TensorFlow 2.X supports the TensorFlow 1.X styled static graph in the sub-module `tf.compat.v1`.\n",
    "\n",
    "This is just for memorial and we do NOT recommend this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello world'\n"
     ]
    }
   ],
   "source": [
    "g = tf.compat.v1.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.compat.v1.placeholder(name='x', shape=[], dtype=tf.string)\n",
    "    y = tf.compat.v1.placeholder(name='y', shape=[], dtype=tf.string)\n",
    "    z = tf.strings.join([x,y],name = \"join\",separator = \" \")\n",
    "\n",
    "with tf.compat.v1.Session(graph = g) as sess:\n",
    "    # fetches is similar to the returning value from a function, while the placeholders in feed_dict is the input argument list to this function\n",
    "    result = sess.run(fetches = z,feed_dict = {x:\"hello\",y:\"world\"})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The Dynamic Graph\n",
    "\n",
    "\n",
    "TensorFlow 2.X uses the dynamic graph and Autograph.\n",
    "\n",
    "In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in `Session`.\n",
    "\n",
    "However, the definition and execution is no more distinguishable for dynamic graph. It executes immediatly after definition and that's the reason why it is called \"Eager Excution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# The construction of the graph takes place at every operator, and the graph execution is immediately following each construction.\n",
    "\n",
    "x = tf.constant(\"hello\")\n",
    "y = tf.constant(\"world\")\n",
    "z = tf.strings.join([x,y],separator=\" \")\n",
    "\n",
    "tf.print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "tf.Tensor(b'hello world', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# The input/output of the dynamic graph could be packaged as a function\n",
    "\n",
    "def strjoin(x,y):\n",
    "    z =  tf.strings.join([x,y],separator = \" \")\n",
    "    tf.print(z)\n",
    "    return z\n",
    "\n",
    "result = strjoin(tf.constant(\"hello\"),tf.constant(\"world\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Autograph in TensorFlow 2.X\n",
    "\n",
    "\n",
    "The dynamic graph has a relatively lower efficiency in execution.\n",
    "\n",
    "We can use the decorator `@tf.function` to convert the original Python functions into the static graph as TensorFlow 1.Xã€‚\n",
    "\n",
    "In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in `Session`.\n",
    "\n",
    "In TensorFlow 2.X, the two steps for Autographs are: defining the function and calling this function.\n",
    "\n",
    "The is no need to use `Session`, so the syntax is as smooth as that of original Python.\n",
    "\n",
    "In reality, we will debug with the dynamic graph, and shift to Autograph using decorator `@tf.function` for the code requires higher efficiency of execution.\n",
    "\n",
    "There are certain rules of implementing `@tf.function`, which will be introduced in the following chapters.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "tf.Tensor(b'hello world', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Use Autograph to construct the static graph\n",
    "\n",
    "@tf.function\n",
    "def strjoin(x,y):\n",
    "    z =  tf.strings.join([x,y],separator = \" \")\n",
    "    tf.print(z)\n",
    "    return z\n",
    "\n",
    "result = strjoin(tf.constant(\"hello\"),tf.constant(\"world\"))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Create log\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = './data/autograph/%s' % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Start tracing on Autograph\n",
    "tf.summary.trace_on(graph=True, profiler=True) \n",
    "\n",
    "# Execute Autograph\n",
    "result = strjoin(\"hello\",\"world\")\n",
    "\n",
    "# Write the graph info into the log\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name=\"autograph\",\n",
    "        step=0,\n",
    "        profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic command to launch tensorboard in jupyter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-df70a09b24b11ace\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-df70a09b24b11ace\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6010;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch tensorboard\n",
    "%tensorboard --logdir ./data/autograph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
